{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/afwebb/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "from attention import AttentionLayer\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-match winning streak</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customers save tax</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢ÂÂ¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claims are not true: Sonam</td>\n",
       "      <td>Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             headlines  \\\n",
       "0    upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "1         Delhi techie wins free food from Swiggy for one year on CRED   \n",
       "2     New Zealand end Rohit Sharma-led India's 12-match winning streak   \n",
       "3             Aegon life iTerm insurance plan helps customers save tax   \n",
       "4  Have known Hirani for yrs, what if MeToo claims are not true: Sonam   \n",
       "\n",
       "                                                                                                                                                                                                      text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...  \n",
       "1  Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...  \n",
       "2  New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...  \n",
       "3  With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢ÂÂ¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, c...  \n",
       "4  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('news_summary_more.csv', encoding='ISO-8859-1')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll clean up the text - removing special character, expanding contractions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCIES = {\n",
    "    \"$\": \"USD\", \"zł\": \"PLN\", \"£\": \"GBP\", \"¥\": \"JPY\", \"฿\": \"THB\", \"₡\": \"CRC\", \"₦\": \"NGN\",\"₩\": \"KRW\",\n",
    "    \"₪\": \"ILS\", \"₫\": \"VND\", \"€\": \"EUR\", \"₱\": \"PHP\", \"₲\": \"PYG\", \"₴\": \"UAH\", \"₹\": \"INR\",}\n",
    "CURRENCY_REGEX = re.compile(\n",
    "    \"({})+\".format(\"|\".join(re.escape(c) for c in CURRENCIES.keys())))\n",
    "\n",
    "EMAIL_REGEX = re.compile(\n",
    "    r\"(?:^|(?<=[^\\w@.)]))([\\w+-](\\.(?!\\.))?)*?[\\w+-]@(?:\\w-?)*?\\w+(\\.([a-z]{2,})){1,3}(?:$|(?=\\b))\",\n",
    "    flags=re.IGNORECASE | re.UNICODE,)\n",
    "\n",
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions =          {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\", \"i've\": \"i have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will apply our cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    \n",
    "    text = text.lower()\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "        \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = EMAIL_REGEX.sub(' ',text)\n",
    "    text = CURRENCY_REGEX.sub(' ',text)\n",
    "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(\" \")])    \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r\"'s\\b\",\"\", text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the text cleaning to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headlines are complete.\n",
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "cleaned_headlines = []\n",
    "cleaned_text = []\n",
    "\n",
    "for headlines in reviews['headlines']:\n",
    "    cleaned_headlines.append(clean_text(headlines, remove_stopwords=False))\n",
    "print(\"Headlines are complete.\")\n",
    "\n",
    "for text in reviews['text']:\n",
    "    cleaned_text.append(clean_text(text))\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: \n",
      "upgrad learner switches to career in ml   al with 90  salary hike\n",
      "Text:\n",
      "saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike upgrad online power learning powered 3 lakh careers\n",
      "\n",
      "Headline: \n",
      "delhi techie wins free food from swiggy for one year on cred\n",
      "Text:\n",
      "kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit\n",
      "\n",
      "Headline: \n",
      "new zealand end rohit sharma led india 12 match winning streak\n",
      "Text:\n",
      "new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back march 2018 match witnessed india getting 92 seventh lowest total odi cricket history\n",
      "\n",
      "Headline: \n",
      "aegon life iterm insurance plan helps customers save tax\n",
      "Text:\n",
      "aegon life iterm insurance plan customers enjoy tax benefits premiums paid save ã¢ââ¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability accidental death benefit rider life cover age 80 years\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for h, t in zip(cleaned_headlines[:4], cleaned_text[:4]):\n",
    "    print('Headline: ')\n",
    "    print(h)\n",
    "    print('Text:')\n",
    "    print(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the length of the text, see how long typical headlines are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "text_word_count = [len(i.split()) for i in cleaned_text]\n",
    "headlines_word_count = [len(i.split()) for i in cleaned_headlines]\n",
    "\n",
    "length_df = pd.DataFrame({'text': text_word_count, 'headlines': headlines_word_count})\n",
    "length_df.hist(bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there aren't any serious outliers in terms of length. We'll set a cutoff of 15 for headlines, 50 for text, to ensure we know how long of a string to expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_headlines_len=15\n",
    "max_text_len=50\n",
    "\n",
    "cleaned_text = np.array(cleaned_text)\n",
    "cleaned_headlines = np.array(cleaned_headlines)\n",
    "\n",
    "short_text=[]\n",
    "short_headlines=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    \n",
    "    if(len(cleaned_headlines[i].split())<=max_headlines_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_headlines.append(cleaned_headlines[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, split the data into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'text':short_text,'headlines':short_headlines})\n",
    "df['headlines'] = df['headlines'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['headlines']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize our input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 61.76182417386657\n",
      "Total Coverage of rare words: 2.482794671181966\n",
      "34345\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n",
    "\n",
    "print(x_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 71.21708892200695\n",
      "Total Coverage of rare words: 4.903581582941041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88335, 88335)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "thresh=6\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_headlines_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_headlines_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1\n",
    "\n",
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove index values from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)\n",
    "\n",
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define our LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7f30a839e5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7f30a839e5f8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7f30a839e5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7f30a839e5f8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 110)      3777950     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 200), (N 248800      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 200), (N 320800      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 110)    1274790     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 200), (N 320800      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 200),  248800      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 200),  80200       lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 400)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 11589)  4647189     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,919,329\n",
      "Trainable params: 10,919,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 200\n",
    "embedding_dim=110\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/afwebb/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 88335 samples, validate on 9814 samples\n",
      "Epoch 1/12\n",
      "88335/88335 [==============================] - 1360s 15ms/sample - loss: 5.1746 - val_loss: 4.7723\n",
      "Epoch 2/12\n",
      "88335/88335 [==============================] - 1597s 18ms/sample - loss: 4.5575 - val_loss: 4.2572\n",
      "Epoch 3/12\n",
      "88335/88335 [==============================] - 1739s 20ms/sample - loss: 4.1338 - val_loss: 3.9696\n",
      "Epoch 4/12\n",
      "88335/88335 [==============================] - 1746s 20ms/sample - loss: 3.8597 - val_loss: 3.7886\n",
      "Epoch 5/12\n",
      "88335/88335 [==============================] - 1747s 20ms/sample - loss: 3.6570 - val_loss: 3.6630\n",
      "Epoch 6/12\n",
      "88335/88335 [==============================] - 1744s 20ms/sample - loss: 3.4950 - val_loss: 3.5698\n",
      "Epoch 7/12\n",
      "88335/88335 [==============================] - 1737s 20ms/sample - loss: 3.3588 - val_loss: 3.5050\n",
      "Epoch 8/12\n",
      "88335/88335 [==============================] - 1729s 20ms/sample - loss: 3.2412 - val_loss: 3.4521\n",
      "Epoch 9/12\n",
      "88335/88335 [==============================] - 1724s 20ms/sample - loss: 3.1392 - val_loss: 3.4069\n",
      "Epoch 10/12\n",
      "88335/88335 [==============================] - 1729s 20ms/sample - loss: 3.0474 - val_loss: 3.3735\n",
      "Epoch 11/12\n",
      "88335/88335 [==============================] - 1722s 19ms/sample - loss: 2.9650 - val_loss: 3.3455\n",
      "Epoch 12/12\n",
      "88335/88335 [==============================] - 1721s 19ms/sample - loss: 2.8886 - val_loss: 3.3230\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], epochs=12,callbacks=[es],\n",
    "                  batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelAbstract.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7f30a839e5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7f30a839e5f8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7f30a839e5f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7f30a839e5f8>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index\n",
    "\n",
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_headlines_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: mohammad kaif yuvraj singh among five cricketers india 2000 19 world cup winning squad went represent senior team india 2008 19 world cup winning squad virat kohli ravindra jadeja abhinav mukund manish pandey saurabh tiwary played team india meanwhile player represent india 2012 squad sandeep sharma \n",
      "Original summary: which u 19 wc winning indian players team india \n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,50]\n\t [[node input_1 (defined at <ipython-input-16-4c1f81035378>:45) ]] [Op:__inference_keras_scratch_graph_64345]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b1a9c755a329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-4c1f81035378>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,50]\n\t [[node input_1 (defined at <ipython-input-16-4c1f81035378>:45) ]] [Op:__inference_keras_scratch_graph_64345]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
